{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a94390a-eb9b-4be2-a116-eca38d9e5ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483142\n",
      "50000\n",
      "59071\n",
      "533142\n"
     ]
    }
   ],
   "source": [
    "#read triples from training set\n",
    "training_f = 'kbc/src_data/FB15K/original/train'\n",
    "train_triples = []\n",
    "with open(training_f, 'r') as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if line:\n",
    "            # two relations split by ',', confidence split by tab\n",
    "            line.replace('\\n', '')\n",
    "            lhs = (line.split('\\t')[0])\n",
    "            rel = (line.split('\\t')[1])\n",
    "            rhs = (line.split('\\t')[2])\n",
    "            \n",
    "#             if rel in rel_head_idx:\n",
    "            train_triples.append((lhs, rel, rhs))\n",
    "        else:\n",
    "            break\n",
    "print(len(train_triples))\n",
    "\n",
    "valid_f = 'kbc/src_data/FB15K/original/valid'\n",
    "valid_triples = []\n",
    "with open(valid_f, 'r') as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if line:\n",
    "            # two relations split by ',', confidence split by tab\n",
    "            line.replace('\\n', '')\n",
    "            lhs = (line.split('\\t')[0])\n",
    "            rel = (line.split('\\t')[1])\n",
    "            rhs = (line.split('\\t')[2])\n",
    "            \n",
    "#             if rel in rel_head_idx:\n",
    "            valid_triples.append((lhs, rel, rhs))\n",
    "        else:\n",
    "            break\n",
    "print(len(valid_triples))\n",
    "\n",
    "test_f = 'kbc/src_data/FB15K/original/test'\n",
    "test_triples = []\n",
    "with open(test_f, 'r') as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if line:\n",
    "            # two relations split by ',', confidence split by tab\n",
    "            line.replace('\\n', '')\n",
    "            lhs = (line.split('\\t')[0])\n",
    "            rel = (line.split('\\t')[1])\n",
    "            rhs = (line.split('\\t')[2])\n",
    "            \n",
    "#             if rel in rel_head_idx:\n",
    "            test_triples.append((lhs, rel, rhs))\n",
    "        else:\n",
    "            break\n",
    "print(len(test_triples))\n",
    "\n",
    "print(len(set(train_triples + valid_triples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cb7a1a9e-3c50-43ec-8924-5f7fdca9ac26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "55\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# read in all rules (using non-circular rules for now)\n",
    "rule_path = 'kbc/src_data/FB237/original/_entailment_cons.txt'\n",
    "#### read in & convert rule ids and confidence\n",
    "kbc_id_conf_f = rule_path\n",
    "r_p_list = []\n",
    "r_q_list = []\n",
    "conf_list = []\n",
    "neg_list = []\n",
    "r_q_dict = defaultdict(list)\n",
    "with open(kbc_id_conf_f, 'r') as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if line:\n",
    "            # two relations split by ',', confidence split by tab\n",
    "            line.replace('\\n', '')\n",
    "            if '-' in line:\n",
    "                neg_list.append(-1)\n",
    "                line = line[1:]\n",
    "            else:\n",
    "                neg_list.append(1)\n",
    "            r_p = line.split(',')[0]\n",
    "            r_q = line.split(',')[1].split('\\t')[0]\n",
    "            conf = line.split('\\t')[1]\n",
    "            # print(rel0, rel1, conf)\n",
    "            r_p_list.append(r_p)\n",
    "            r_q_list.append(r_q)\n",
    "            conf_list.append(conf)\n",
    "            r_q_dict[r_q].append(r_p)\n",
    "        else:\n",
    "            break\n",
    "rule_list = [r_p_list, r_q_list, conf_list, neg_list]\n",
    "r_set = set(r_p_list + r_q_list)\n",
    "print(len(rule_list[0]))\n",
    "print(len(r_set))\n",
    "print(len(set(r_p_list) - set(r_q_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d598f3-7b02-4c66-b8df-79d8ebbc9863",
   "metadata": {},
   "source": [
    "# Transductive experiments:\n",
    "## Keep only some triplets of all head relations:\n",
    "1. For all rp, in training set, keep only one (e1, rp, e2) for all (e1, rp, _)\n",
    "2. For rp â†’ rq, if (e1, rp, e2), Remove: (e1, rq, _) and (_, rq, e2), (e2, rq, e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "626d5549-b6ee-4cad-a343-710eae36ec04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272115\n",
      "272115\n",
      "264964\n"
     ]
    }
   ],
   "source": [
    "tmp_triples = train_triples.copy()\n",
    "print(len(train_triples))\n",
    "print(len(tmp_triples))\n",
    "seen_dict = {}\n",
    "cnt = 0\n",
    "for e1, r, e2 in train_triples:\n",
    "    for (r_p, r_q) in zip(r_p_list, r_q_list):\n",
    "        if r == r_p and r_p != r_q:\n",
    "            if (e1, r) in seen_dict:\n",
    "                try:\n",
    "                    tmp_triples.remove((e1, r, e2))\n",
    "                    break\n",
    "                except: \n",
    "                    pass\n",
    "            else:\n",
    "                seen_dict[(e1, r)] = (e1, r, e2)\n",
    "                break\n",
    "print(len(tmp_triples))\n",
    "train_triples = tmp_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fff266-c10c-40b7-be81-d838c9e6dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_triples)\n",
    "new_train_file = open('kbc/src_data/FB237/train_1004', \"w\")\n",
    "for e1, r, e2 in train_triples:\n",
    "    new_train_file.write(str(e1) + '\\t' + str(r) + '\\t' + str(e2))\n",
    "new_train_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d54a64-7461-4878-af05-6e0ed6784941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraction done\n",
      "261149\n",
      "4547\n",
      "17500\n"
     ]
    }
   ],
   "source": [
    "# filter out some triples with head relations\n",
    "entailment_triples = set()\n",
    "remove_triples = []\n",
    "test_triples = set()\n",
    "head_set = set()\n",
    "tail_set = set()\n",
    "cnt = 0\n",
    "# for e1, r, e2 in train_triples:\n",
    "#     if cnt % 5000 == 0:\n",
    "#         print(cnt)\n",
    "#     cnt += 1\n",
    "#     for (r_p, r_q) in zip(r_p_list, r_q_list):\n",
    "#         if r == r_p and r_p != r_q:\n",
    "#             test_triples.append((e1, r_q, e2))\n",
    "# #             print(e1, r, e2, r_p, r_q)\n",
    "#             tmp = [i for i in train_triples if (i[0] == e1 and i[1] == r_q and i[2] != e2) or (i[0] != e1 and i[1] == r_q and i[2] == e2) or (i[0] == e2 and i[1] == r_q and i[2] != e1) or (i[0] != e2 and i[1] == r_q and i[2] == e1)]\n",
    "#             if len(tmp): \n",
    "# #                 print((tmp[0]))\n",
    "#                 remove_triples += tmp\n",
    "    \n",
    "# remove_triples = list(set(remove_triples))\n",
    "# print(\"extraction done\")\n",
    "# entailment_triples = [i for i in train_triples if i not in remove_triples]\n",
    "# print(len(entailment_triples))\n",
    "# print(len(test_triples))\n",
    "\n",
    "for e1, r, e2 in train_triples:\n",
    "    dup = 0\n",
    "    for (r_p, r_q) in zip(r_p_list, r_q_list):\n",
    "        if r == r_p and r_p != r_q:\n",
    "            test_triples.add((e1, r_q, e2))\n",
    "            if ((e1, r) in head_set) or ((r, e2) in tail_set):\n",
    "                # duplicate, skip\n",
    "                dup = 1\n",
    "                break\n",
    "            else:\n",
    "                entailment_triples.add((e1, r, e2))\n",
    "                head_set.add((e1, r))\n",
    "                tail_set.add((r, e2))\n",
    "    if not dup:\n",
    "        entailment_triples.add((e1, r, e2))\n",
    "    \n",
    "# remove_triples = list(set(remove_triples))\n",
    "print(\"extraction done\")\n",
    "# entailment_triples = [i for i in train_triples if i not in remove_triples]\n",
    "entailment_triples = list(entailment_triples)\n",
    "print(len(entailment_triples))\n",
    "print(len(test_triples))\n",
    "\n",
    "# filter out some triples with head relations from valid set\n",
    "entailment_valid_triples = set()\n",
    "remove_valid_triples = []\n",
    "head_set = set()\n",
    "tail_set = set()\n",
    "cnt = 0\n",
    "for e1, r, e2 in valid_triples:\n",
    "    dup = 0\n",
    "    for (r_p, r_q) in zip(r_p_list, r_q_list):\n",
    "        if r == r_p and r_p != r_q:\n",
    "            if ((e1, r) in head_set) or ((r, e2) in tail_set):\n",
    "                # duplicate, skip\n",
    "                dup = 1\n",
    "                break\n",
    "            else:\n",
    "                head_set.add((e1, r))\n",
    "                tail_set.add((r, e2))\n",
    "                entailment_valid_triples.add((e1, r, e2))\n",
    "    if not dup:\n",
    "        entailment_valid_triples.add((e1, r, e2))\n",
    "\n",
    "entailment_valid_triples = list(entailment_valid_triples)\n",
    "print(len(entailment_valid_triples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae102b0e-55f8-438f-b8cb-8f0b0607aa93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4547"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(remove_triples)\n",
    "test_triples = list(set(test_triples))\n",
    "len(test_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09d17381-4884-4753-90be-15201ba7b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save triples to file\n",
    "new_train_file = open('kbc/src_data/FB237/train_1004', \"w\")\n",
    "for e1, r, e2 in entailment_triples:\n",
    "    new_train_file.write(str(e1) + '\\t' + str(r) + '\\t' + str(e2))\n",
    "new_train_file.close()\n",
    "\n",
    "new_valid_file = open('kbc/src_data/FB237/valid_1004', \"w\")\n",
    "for e1, r, e2 in tmp_valid_triples:\n",
    "    new_valid_file.write(str(e1) + '\\t' + str(r) + '\\t' + str(e2))\n",
    "new_valid_file.close()\n",
    "\n",
    "new_test_file = open('kbc/src_data/FB237/test_1004', \"w\")\n",
    "for e1, r, e2 in test_triples:\n",
    "    new_test_file.write(str(e1) + '\\t' + str(r) + '\\t' + str(e2))\n",
    "new_test_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829f5e63-3205-4dab-9322-784ed2cccb63",
   "metadata": {},
   "source": [
    "# Inductive experiments:\n",
    "Randomly select from test set, omit any tuples from the training file with the entity in the new test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4993c785-ff18-41b0-a16f-609dfa17fee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20466\n"
     ]
    }
   ],
   "source": [
    "#read triples from test set\n",
    "test_f = 'kbc/src_data/FB237/original/test'\n",
    "test_triples = []\n",
    "with open(test_f, 'r') as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if line:\n",
    "            # two relations split by ',', confidence split by tab\n",
    "            line.replace('\\n', '')\n",
    "            lhs = (line.split('\\t')[0])\n",
    "            rel = (line.split('\\t')[1])\n",
    "            rhs = (line.split('\\t')[2])\n",
    "            \n",
    "            test_triples.append((lhs, rel, rhs))\n",
    "        else:\n",
    "            break\n",
    "print(len(test_triples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "202b6489-bb5c-4b60-a785-7b8c5cb960b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4093\n",
      "5256\n"
     ]
    }
   ],
   "source": [
    "# randomly select 30% of triples, extract entities\n",
    "import random\n",
    "sample_num = len(test_triples) * 20 // 100\n",
    "sample_test_triples = random.sample(test_triples, sample_num)\n",
    "print(len(sample_test_triples))\n",
    "ent_set = set()\n",
    "for triple in sample_test_triples:\n",
    "    ent_set.add(triple[0])\n",
    "    ent_set.add(triple[2])\n",
    "print(len(ent_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d777aae-ff82-4836-b84f-667bd52a2f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79778\n",
      "3549\n"
     ]
    }
   ],
   "source": [
    "# omit entities from training and valid set\n",
    "tmp_triples = train_triples.copy()\n",
    "for triple in train_triples:\n",
    "    if triple[0] in ent_set or triple[2] in ent_set:\n",
    "        tmp_triples.remove(triple)\n",
    "print(len(tmp_triples))\n",
    "# train_triples = tmp_triples\n",
    "\n",
    "tmp_valid_triples = valid_triples.copy()\n",
    "for triple in valid_triples:\n",
    "    if triple[0] in ent_set or triple[2] in ent_set:\n",
    "        tmp_valid_triples.remove(triple)\n",
    "print(len(tmp_valid_triples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab935746-7067-4192-8332-dee37b9efd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save triples to file\n",
    "new_train_file = open('kbc/src_data/FB237/train_1007', \"w\")\n",
    "for e1, r, e2 in tmp_triples:\n",
    "    new_train_file.write(str(e1) + '\\t' + str(r) + '\\t' + str(e2))\n",
    "new_train_file.close()\n",
    "\n",
    "new_valid_file = open('kbc/src_data/FB237/valid_1007', \"w\")\n",
    "for e1, r, e2 in tmp_valid_triples:\n",
    "    new_valid_file.write(str(e1) + '\\t' + str(r) + '\\t' + str(e2))\n",
    "new_valid_file.close()\n",
    "\n",
    "new_test_file = open('kbc/src_data/FB237/test_1007', \"w\")\n",
    "for e1, r, e2 in sample_test_triples:\n",
    "    new_test_file.write(str(e1) + '\\t' + str(r) + '\\t' + str(e2))\n",
    "new_test_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a937787-d6e7-4b08-85a3-50b23fe655ae",
   "metadata": {},
   "source": [
    "# Synthesized experiments(10.14):\n",
    "- For (e1, r, e2) in test and r in r_q set, we don't want (e1, r, _), (_, r, e2) to be seen in training and valid set, but we still want e1, r, e2, (e1, r_p, e2) to be seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac099fd7-67ca-49fd-9ac6-41b121da42df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "719\n"
     ]
    }
   ],
   "source": [
    "# remove unrelevant test triples\n",
    "new_test_triples = []\n",
    "r_q_set = set(r_q_list)\n",
    "print(len(r_q_set))\n",
    "for e1, r, e2 in test_triples:\n",
    "    if r in r_q_set:\n",
    "        new_test_triples.append((e1, r, e2))\n",
    "print(len(new_test_triples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06b2ba7e-e058-4d7c-8329-8646597d59d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650\n",
      "635\n",
      "252430\n",
      "17336\n",
      "253220\n",
      "18103\n"
     ]
    }
   ],
   "source": [
    "head_set = set()\n",
    "tail_set = set()\n",
    "extract_train_triples = set()\n",
    "extract_valid_triples = set()\n",
    "for e1, r, e2 in test_triples:\n",
    "    for (r_p, r_q) in zip(r_p_list, r_q_list):\n",
    "        if r == r_q:\n",
    "            head_set.add((e1, r))\n",
    "#             head_set.add((e1, r_p))\n",
    "            tail_set.add((r, e2))\n",
    "#             tail_set.add((r_p, e2))\n",
    "print(len(head_set))\n",
    "print(len(tail_set))\n",
    "for e1, r, e2 in train_triples:\n",
    "    if (e1, r) not in head_set and (r, e2) not in tail_set:\n",
    "        extract_train_triples.add((e1, r, e2))\n",
    "print(len(extract_train_triples))\n",
    "\n",
    "for e1, r, e2 in valid_triples:\n",
    "    if (e1, r) not in head_set and (r, e2) not in tail_set:\n",
    "        extract_valid_triples.add((e1, r, e2))\n",
    "print(len(extract_valid_triples))\n",
    "\n",
    "# add tail triples to training and valid sets\n",
    "for e1, r, e2 in new_test_triples:\n",
    "    for r_p in r_q_dict[r]:\n",
    "        extract_valid_triples.add((e1, r_p, e2))\n",
    "        extract_triples.add((e1, r_p, e2))\n",
    "print(len(extract_triples))\n",
    "print(len(extract_valid_triples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48c9cf5a-1df2-437a-a54c-1c3f0bd07091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save triples to file\n",
    "new_train_file = open('kbc/src_data/FB237/train_1014', \"w\")\n",
    "for e1, r, e2 in extract_train_triples:\n",
    "    new_train_file.write(str(e1) + '\\t' + str(r) + '\\t' + str(e2))\n",
    "new_train_file.close()\n",
    "\n",
    "new_valid_file = open('kbc/src_data/FB237/valid_1014', \"w\")\n",
    "for e1, r, e2 in extract_valid_triples:\n",
    "    new_valid_file.write(str(e1) + '\\t' + str(r) + '\\t' + str(e2))\n",
    "new_valid_file.close()\n",
    "\n",
    "new_test_file = open('kbc/src_data/FB237/test_1014', \"w\")\n",
    "for e1, r, e2 in new_test_triples:\n",
    "    new_test_file.write(str(e1) + '\\t' + str(r) + '\\t' + str(e2))\n",
    "new_test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "721fed16-bae2-4f2b-970b-08d9a7f43aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20466\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "print(len(test_triples))\n",
    "print(len(r_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b3a8083-94f2-4faa-ad46-222c2a414d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_file = open('kbc/src_data/FB237/test_1014', \"w\")\n",
    "for e1, r, e2 in new_test_triples:\n",
    "    new_test_file.write(str(e1) + '\\t' + str(r) + '\\t' + str(e2))\n",
    "new_test_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff729c7-ee8e-4d38-82f1-dfb6178fd57b",
   "metadata": {},
   "source": [
    "# Synthesized experiments(11.14):\n",
    "- Create \"low_freq relation/entity\" test set\n",
    "    - for all r_q, extract all triples from training & test set\n",
    "    - add all such triples to test set (remove redundent), keep only 1 (is this enough?) r_q triple in training set (let the model learn r_q, low_freq, solve the lack of test triple problem)\n",
    "    - only have **8 rules** (r_q not in r_p set)\n",
    "- Validate effect of r_q freq in training set (12.7)\n",
    "    - add all such triples to test set (remove redundent), sample different numbers (1, 2, 4, 8) of r_q triples into training set (let the model learn r_q, low_freq, solve the lack of test triple problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "27c9e94a-8d06-46ac-bcf8-f46a4baedb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "16\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# read in all rules (using rules that r_q are not as r_p as well)\n",
    "rule_path = 'kbc/src_data/FB237/original/_entailment_cons-rq.txt'\n",
    "#### read in & convert rule ids and confidence\n",
    "kbc_id_conf_f = rule_path\n",
    "r_p_list = []\n",
    "r_q_list = []\n",
    "conf_list = []\n",
    "neg_list = []\n",
    "r_q_dict = defaultdict(list)\n",
    "with open(kbc_id_conf_f, 'r') as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if line:\n",
    "            # two relations split by ',', confidence split by tab\n",
    "            line.replace('\\n', '')\n",
    "            if '-' in line:\n",
    "                neg_list.append(-1)\n",
    "                line = line[1:]\n",
    "            else:\n",
    "                neg_list.append(1)\n",
    "            r_p = line.split(',')[0]\n",
    "            r_q = line.split(',')[1].split('\\t')[0]\n",
    "            conf = line.split('\\t')[1]\n",
    "            # print(rel0, rel1, conf)\n",
    "            r_p_list.append(r_p)\n",
    "            r_q_list.append(r_q)\n",
    "            conf_list.append(conf)\n",
    "            r_q_dict[r_q].append(r_p)\n",
    "        else:\n",
    "            break\n",
    "rule_list = [r_p_list, r_q_list, conf_list, neg_list]\n",
    "r_set = set(r_p_list + r_q_list)\n",
    "print(len(rule_list[0]))\n",
    "print(len(r_set))\n",
    "print(len(set(r_p_list) - set(r_q_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e05dd083-8336-4f97-9afe-f951bfc0e129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2245\n",
      "8\n",
      "2253\n"
     ]
    }
   ],
   "source": [
    "# extract all relevant triples in original train, valid and test data\n",
    "# keep sample_num for each relation at training and valid\n",
    "r_q_set = set(r_q_list) - set(r_p_list)\n",
    "# print(r_q_set)\n",
    "r_dict = defaultdict(list)\n",
    "for e1, r, e2 in train_triples + test_triples + valid_triples:\n",
    "    if r in r_q_set:\n",
    "        r_dict[r].append((e1, r, e2))\n",
    "# sample for each relation r_q\n",
    "from random import sample\n",
    "train_num = 1\n",
    "test_num = 80\n",
    "extracted_test_triples = []\n",
    "cand_triples = []\n",
    "all_r_q_triples = set()\n",
    "for r in r_dict:\n",
    "    all_r_q_triples |= set(r_dict[r])\n",
    "    train_r = sample(r_dict[r], train_num)\n",
    "    cand_triples += train_r\n",
    "    test_r = list(set(r_dict[r]) - set(train_r))\n",
    "    extracted_test_triples += test_r\n",
    "print(len(extracted_test_triples))\n",
    "print(len(cand_triples))\n",
    "print(len(all_r_q_triples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c1955d95-062b-4b98-9bc9-9d2ba2fbf028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269915\n",
      "17521\n"
     ]
    }
   ],
   "source": [
    "# all r_q relevant triples should be removed from original training and testing\n",
    "extract_train_triples = set()\n",
    "extract_valid_triples = set()\n",
    "for t in train_triples:\n",
    "    if t not in all_r_q_triples:\n",
    "        extract_train_triples.add(t)\n",
    "extract_train_triples = extract_train_triples | set(cand_triples)\n",
    "print(len(extract_train_triples))\n",
    "\n",
    "for t in valid_triples:\n",
    "    if t not in all_r_q_triples:\n",
    "        extract_valid_triples.add(t)\n",
    "extract_valid_triples |= set(cand_triples)\n",
    "print(len(extract_valid_triples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "86856478-8cab-491d-8b9e-67c5a0f106be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2189\n"
     ]
    }
   ],
   "source": [
    "# use for all sampling tests\n",
    "static_extracted_test_triples = list(extracted_test_triples)\n",
    "print(len(static_extracted_test_triples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d34a49d8-cc0e-4ae7-ab68-95c2c7c72d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save triples to file\n",
    "new_train_file = open('kbc/src_data/FB237/train_1207_1', \"w\")\n",
    "for e1, r, e2 in extract_train_triples:\n",
    "    new_train_file.write(str(e1) + '\\t' + str(r) + '\\t' + str(e2))\n",
    "new_train_file.close()\n",
    "\n",
    "new_valid_file = open('kbc/src_data/FB237/valid_1207_1', \"w\")\n",
    "for e1, r, e2 in extract_valid_triples:\n",
    "    new_valid_file.write(str(e1) + '\\t' + str(r) + '\\t' + str(e2))\n",
    "new_valid_file.close()\n",
    "\n",
    "new_test_file = open('kbc/src_data/FB237/test_1207', \"w\")\n",
    "for e1, r, e2 in static_extracted_test_triples:\n",
    "    new_test_file.write(str(e1) + '\\t' + str(r) + '\\t' + str(e2))\n",
    "new_test_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e355a149-3de7-41e5-859e-96cf6c9007bf",
   "metadata": {},
   "source": [
    "# Validation experiment(12.7):\n",
    "- Create \"validation\" test set to check the correctness of model on low freq training setting (synthesized setting 11.7)\n",
    "    - remove all r_q relevant triples from training & valid set\n",
    "    - for all <e1, rp, e2> in training set, add <e1, rq, e2> into test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "56963a3f-06fe-47bb-8187-1b72942b399c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10224\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "valid_test_triples = set()\n",
    "r_p_set = set(r_p_list)\n",
    "r_p_dict = collections.defaultdict(list)\n",
    "for r_p, r_q in zip(r_p_list, r_q_list):\n",
    "    r_p_dict[r_p].append(r_q)\n",
    "# print(r_p_dict)\n",
    "for e1, r, e2 in (extract_train_triples | extract_valid_triples):\n",
    "    if r in r_p_dict:\n",
    "        for r_q in r_p_dict[r]:\n",
    "            valid_test_triples.add((e1, r_q, e2))\n",
    "print(len(valid_test_triples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8308ad82-660c-4ed0-9531-3f404399bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save triples to file\n",
    "new_train_file = open('kbc/src_data/FB237/train_eval_1207', \"w\")\n",
    "for e1, r, e2 in extract_train_triples:\n",
    "    new_train_file.write(str(e1) + '\\t' + str(r) + '\\t' + str(e2))\n",
    "new_train_file.close()\n",
    "\n",
    "new_valid_file = open('kbc/src_data/FB237/valid_eval_1207', \"w\")\n",
    "for e1, r, e2 in extract_valid_triples:\n",
    "    new_valid_file.write(str(e1) + '\\t' + str(r) + '\\t' + str(e2))\n",
    "new_valid_file.close()\n",
    "\n",
    "new_test_file = open('kbc/src_data/FB237/test_eval_1207', \"w\")\n",
    "for e1, r, e2 in valid_test_triples:\n",
    "    new_test_file.write(str(e1) + '\\t' + str(r) + '\\t' + str(e2))\n",
    "new_test_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce2b6ad-1a3d-4b74-96f5-9919e07aab37",
   "metadata": {},
   "source": [
    "# FB15K:\n",
    "- Rule quality may affect link prediction result\n",
    "    - Entailment rule: try rules with more triples in test/training set\n",
    "    - Type 4: try rules with higher quality (conf > 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15c0488c-13f6-4d9e-ac5a-c35c966071b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535\n"
     ]
    }
   ],
   "source": [
    "rule_path = 'kbc/src_data/FB15K/_cons.txt'\n",
    "rule_list = []\n",
    "with open(rule_path, 'r') as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if line:\n",
    "            flag = 1\n",
    "            # two relations split by ',', confidence split by tab\n",
    "            line.replace('\\n', '')\n",
    "            if line[0] == '-': # negative rules\n",
    "                flag = -1\n",
    "                line = line[1:]\n",
    "            tokens = line.split('\\t')\n",
    "            r_p = tokens[0].split(',')[0]\n",
    "            r_q = (tokens[0].split(',')[1])\n",
    "            conf = float(tokens[1])\n",
    "            # print(r_p, r_q, conf)\n",
    "#             if conf == 1.0 and conf > 0.8:\n",
    "            rule_list.append([r_p, r_q, conf, flag, 0])\n",
    "        else:\n",
    "            break\n",
    "print(len(rule_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22285985-60ce-4817-8a2d-d1af724f9827",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-e518bdafeeb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_triples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrule_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrule_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mrule_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "######## enatilment rules:check how many related triples in test set\n",
    "for e1, r, e2 in test_triples:\n",
    "    for i in range(len(rule_list)):\n",
    "        if r == rule_list[i][1]:\n",
    "            rule_list[i][4] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53d3034f-e1b1-4205-818c-abfa32946eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## enatilment rules:check how many related triples in training set\n",
    "for e1, r, e2 in train_triples:\n",
    "    for i in range(len(rule_list)):\n",
    "        if r == rule_list[i][1]:\n",
    "            rule_list[i][4] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0ed4b86-6460-4012-9a2f-7cbcf0c92b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/award/award_nominee/award_nominations./award/award_nomination/award_nominee', '/award/award_nominee/award_nominations./award/award_nomination/award_nominee', 0.814149284, -1, 15998]\n",
      "['/user/alexander/philosophy/subject/philosophers', '/user/alexander/philosophy/philosopher/interests', 0.831578947, -1, 100]\n"
     ]
    }
   ],
   "source": [
    "rule_list.sort(key=lambda x: x[4], reverse=True)\n",
    "print(rule_list[0])\n",
    "print(rule_list[534])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc655d64-f82a-4d99-8529-b72eb1bc4ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### write in new rule set\n",
    "new_rule_file = open('kbc/src_data/FB15K/_cons_freq_train.txt', \"w\")\n",
    "for r_p, r_q, conf, flag, cnt in rule_list:\n",
    "    rule = str(r_p) + ',' + str(r_q) + '\\t' + str(conf) + '\\n'\n",
    "    if flag == -1:\n",
    "        rule = '-' + rule\n",
    "    new_rule_file.write(rule)\n",
    "new_rule_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e271608b-8fe5-45cb-873a-85877a3396dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
